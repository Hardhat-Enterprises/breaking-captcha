{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28034689",
   "metadata": {},
   "source": [
    "## Image to Text\n",
    "#### https://github.com/AbhishekAnand18/ImageTextRecognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b73d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image as pilImg\n",
    "from os import walk\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "src_path = r'C:\\Users\\User\\breaking-captcha-preprocessingTEXT\\Images2\\Train'\n",
    "# grabbing all the files in the training path and listing them in a data frame\n",
    "\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk(src_path):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    " \n",
    "\n",
    "train_data=pd.DataFrame({'ImageName': f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f10dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007I3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0145A.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02N7Y.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03727.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03F1N.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageName\n",
       "0  007I3.png\n",
       "1  0145A.png\n",
       "2  02N7Y.png\n",
       "3  03727.png\n",
       "4  03F1N.png"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad2afa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ground_truth(files):\n",
    "    \"\"\"\n",
    "    Given the file names of images, extracts the Ground Truth Values and returns a list of Ground Truth Labels in All Capitals\n",
    "    \"\"\"\n",
    "    txt_labels=[]\n",
    "    for file in files:\n",
    "        ground_truth,image=file.split('.')\n",
    "        ground_truth=ground_truth.upper()\n",
    "        txt_labels.append(ground_truth)\n",
    "    return txt_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d1946b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_ground_truths=extract_ground_truth(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d062a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Labels']=Train_ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb8c5c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007I3.png</td>\n",
       "      <td>007I3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0145A.png</td>\n",
       "      <td>0145A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02N7Y.png</td>\n",
       "      <td>02N7Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03727.png</td>\n",
       "      <td>03727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03F1N.png</td>\n",
       "      <td>03F1N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageName Labels\n",
       "0  007I3.png  007I3\n",
       "1  0145A.png  0145A\n",
       "2  02N7Y.png  02N7Y\n",
       "3  03727.png  03727\n",
       "4  03F1N.png  03F1N"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff04e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"Train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48737bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path2 = r'C:\\Users\\User\\breaking-captcha-preprocessingTEXT\\Images2\\Test'\n",
    "# grabbing all the files in the training path and listing them in a data frame\n",
    "\n",
    "k = []\n",
    "for (dirpath, dirnames, filenames) in walk(src_path2):\n",
    "    k.extend(filenames)\n",
    "    break\n",
    " \n",
    "\n",
    "test_data=pd.DataFrame({'ImageName': k})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "460bee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_ground_truths=extract_ground_truth(k)\n",
    "test_data['Labels']=Test_ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d746bf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000NR.png</td>\n",
       "      <td>000NR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00JJF.png</td>\n",
       "      <td>00JJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00XZJ.png</td>\n",
       "      <td>00XZJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01FMR.png</td>\n",
       "      <td>01FMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01UGO.png</td>\n",
       "      <td>01UGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageName Labels\n",
       "0  000NR.png  000NR\n",
       "1  00JJF.png  00JJF\n",
       "2  00XZJ.png  00XZJ\n",
       "3  01FMR.png  01FMR\n",
       "4  01UGO.png  01UGO"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d08421a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('Test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60ec8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c03ecb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image processing -> changing colour to greyscale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4d34ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_store_single_channel(destination_folder,files):\n",
    "    \"\"\"\n",
    "    Takes the images in a folder, distination folder path and \n",
    "    converts the image to single channel gray scale,\n",
    "    stores the image in the destination folder and returns image destination list\n",
    "    \"\"\"\n",
    "    start=datetime.now()\n",
    "    destination_list=[]\n",
    "    count=1\n",
    "    for file in files:\n",
    "        destination=destination_folder+file\n",
    "        cv_img=cv2.imread(file)\n",
    "        #So extracting image from any 1 channel gives a single channel Grayscale image\n",
    "        cv_img_sc=cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(destination,cv_img_sc)\n",
    "        destination_list.append(destination)\n",
    "        count+=1\n",
    "#         if count%10000==0:\n",
    "#             print(\"Processed Images: \",count)\n",
    "    print('Time Taken for Processing: ',datetime.now() - start)\n",
    "    return destination_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9eef9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('Train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79f906de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00eea594",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files=train_data['ImageName'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5273e8c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\User\\\\breaking-captcha-preprocessingTEXT\\\\Train_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m trainData \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbreaking-captcha-preprocessingTEXT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTrain_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainData\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\User\\\\breaking-captcha-preprocessingTEXT\\\\Train_data'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#trainData = r'C:\\Users\\User\\breaking-captcha-preprocessingTEXT\\Train_data'\n",
    "#os.mkdir(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "507d240b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train_dest\u001b[38;5;241m=\u001b[39m\u001b[43mimg_store_single_channel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36mimg_store_single_channel\u001b[1;34m(destination_folder, files)\u001b[0m\n\u001b[0;32m     12\u001b[0m cv_img\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mimread(file)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#So extracting image from any 1 channel gives a single channel Grayscale image\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m cv_img_sc\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(destination,cv_img_sc)\n\u001b[0;32m     16\u001b[0m destination_list\u001b[38;5;241m.\u001b[39mappend(destination)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "train_dest=img_store_single_channel(trainData,train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0c883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
