{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bddd97d",
   "metadata": {},
   "source": [
    "## Image to Text\n",
    "#### https://github.com/AbhishekAnand18/ImageTextRecognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e304da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image as pilImg\n",
    "from os import walk\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "src_path = r'C:\\Users\\User\\breaking-captcha-preprocessingTEXT\\Images2\\Train'\n",
    "# grabbing all the files in the training path and listing them in a data frame\n",
    "\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk(src_path):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    " \n",
    "\n",
    "train_data=pd.DataFrame({'ImageName': f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b9a99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007I3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0145A.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02N7Y.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03727.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03F1N.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageName\n",
       "0  007I3.png\n",
       "1  0145A.png\n",
       "2  02N7Y.png\n",
       "3  03727.png\n",
       "4  03F1N.png"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f89c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ground_truth(files):\n",
    "    \"\"\"\n",
    "    Given the file names of images, extracts the Ground Truth Values and returns a list of Ground Truth Labels in All Capitals\n",
    "    \"\"\"\n",
    "    txt_labels=[]\n",
    "    for file in files:\n",
    "        ground_truth,image=file.split('.')\n",
    "        ground_truth=ground_truth.upper()\n",
    "        txt_labels.append(ground_truth)\n",
    "    return txt_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6068c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_ground_truths=extract_ground_truth(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01cc5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Labels']=Train_ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "060f19c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007I3.png</td>\n",
       "      <td>007I3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0145A.png</td>\n",
       "      <td>0145A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02N7Y.png</td>\n",
       "      <td>02N7Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03727.png</td>\n",
       "      <td>03727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03F1N.png</td>\n",
       "      <td>03F1N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageName Labels\n",
       "0  007I3.png  007I3\n",
       "1  0145A.png  0145A\n",
       "2  02N7Y.png  02N7Y\n",
       "3  03727.png  03727\n",
       "4  03F1N.png  03F1N"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ad2e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"Train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af8c1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path2 = r'C:\\Users\\User\\breaking-captcha-preprocessingTEXT\\Images2\\Test'\n",
    "# grabbing all the files in the training path and listing them in a data frame\n",
    "\n",
    "k = []\n",
    "for (dirpath, dirnames, filenames) in walk(src_path2):\n",
    "    k.extend(filenames)\n",
    "    break\n",
    " \n",
    "\n",
    "test_data=pd.DataFrame({'ImageName': k})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0404c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_ground_truths=extract_ground_truth(k)\n",
    "test_data['Labels']=Test_ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d23bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000NR.png</td>\n",
       "      <td>000NR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00JJF.png</td>\n",
       "      <td>00JJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00XZJ.png</td>\n",
       "      <td>00XZJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01FMR.png</td>\n",
       "      <td>01FMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01UGO.png</td>\n",
       "      <td>01UGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageName Labels\n",
       "0  000NR.png  000NR\n",
       "1  00JJF.png  00JJF\n",
       "2  00XZJ.png  00XZJ\n",
       "3  01FMR.png  01FMR\n",
       "4  01UGO.png  01UGO"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a74e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('Test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "725f930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f23920",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image processing -> changing colour to greyscale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176074a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "85607be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def img_store_single_channel(source_folder,destination_folder,files):\n",
    "    \"\"\"\n",
    "    Takes the images in a folder, distination folder path and \n",
    "    converts the image to single channel gray scale,\n",
    "    stores the image in the destination folder and returns image destination list\n",
    "    \"\"\"\n",
    "    start=datetime.now()\n",
    "    destination_list=[]\n",
    "    count=1\n",
    "    for file in files:\n",
    "        #print(file)\n",
    "        destination=destination_folder+str(count)+'_'+file\n",
    "        #print(destination)\n",
    "        cv_img=cv2.imread(source_folder+file)\n",
    "        #print(cv_img)\n",
    "        #So extracting image from any 1 channel gives a single channel Grayscale image\n",
    "        #cv_img_sc=cv_resized[:,:,1]\n",
    "        cv_img_sc=cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(destination,cv_img_sc)\n",
    "        destination_list.append(destination)\n",
    "        count+=1\n",
    "        #if count%10000==0:\n",
    "            #print(\"Processed Images: \",count)\n",
    "    print('Time Taken for Processing: ',datetime.now() - start)\n",
    "    return destination_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "73fd39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('Train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "de57fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a0dd17b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['007I3.png' '0145A.png' '02N7Y.png' ... 'ZY44Q.png' 'ZZ493.png'\n",
      " 'ZZMM9.png']\n"
     ]
    }
   ],
   "source": [
    "train_files=train_data['ImageName'].values\n",
    "print(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "811c5da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\breaking-captcha-preprocessingTEXT\n"
     ]
    }
   ],
   "source": [
    "directory = os.getcwd()\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b75d5d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\breaking-captcha-preprocessingTEXT\\Train_data2\n",
      "C:\\Users\\User\\breaking-captcha-preprocessingTEXT\\Images2\\Train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "trainData2 = r'C:\\Users\\User\\breaking-captcha-preprocessingTEXT\\Train_data2'\n",
    "os.mkdir(trainData2)\n",
    "print(trainData2)\n",
    "print(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "73f437e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken for Processing:  0:00:06.369686\n"
     ]
    }
   ],
   "source": [
    "train_dest=img_store_single_channel(src_path+'\\\\',trainData2+'\\\\',train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "cdff4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['ImageName']=train_dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e4a822ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()\n",
    "train_data.to_csv('Train_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "115d02b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\breaking-captcha-preprocessingTEXT\\Test_data2\n",
      "C:\\Users\\User\\breaking-captcha-preprocessingTEXT\\Images2\\Test\n"
     ]
    }
   ],
   "source": [
    "testData2 = r'C:\\Users\\User\\breaking-captcha-preprocessingTEXT\\Test_data2'\n",
    "#os.mkdir(testData2)\n",
    "print(testData2)\n",
    "print(src_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "665df04f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # processing Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f46a4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('Test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e845d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1b686018",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files=test_data['ImageName'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b0888ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken for Processing:  0:00:10.803081\n"
     ]
    }
   ],
   "source": [
    "test_dest=img_store_single_channel(src_path2+'\\\\',testData2+'\\\\',test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5c3a8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['ImageName']=test_dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "dcd50290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\User\\breaking-captcha-preprocessingTE...</td>\n",
       "      <td>000NR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\User\\breaking-captcha-preprocessingTE...</td>\n",
       "      <td>00JJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\User\\breaking-captcha-preprocessingTE...</td>\n",
       "      <td>00XZJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\User\\breaking-captcha-preprocessingTE...</td>\n",
       "      <td>01FMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\User\\breaking-captcha-preprocessingTE...</td>\n",
       "      <td>01UGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ImageName Labels\n",
       "0  C:\\Users\\User\\breaking-captcha-preprocessingTE...  000NR\n",
       "1  C:\\Users\\User\\breaking-captcha-preprocessingTE...  00JJF\n",
       "2  C:\\Users\\User\\breaking-captcha-preprocessingTE...  00XZJ\n",
       "3  C:\\Users\\User\\breaking-captcha-preprocessingTE...  01FMR\n",
       "4  C:\\Users\\User\\breaking-captcha-preprocessingTE...  01UGO"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c9090169",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('Test_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6e8b48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "de56b20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b04fa53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=b9865befadaf373e4fe7036701b8100fa2d710e5923f600e15415f6359208d88\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 flatbuffers-2.0.7 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-preprocessing-1.1.2 libclang-14.0.6 oauthlib-3.2.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-1.1.0\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Using cached tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 flatbuffers-2.0.7 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-preprocessing-1.1.2 libclang-14.0.6 oauthlib-3.2.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc72bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import random\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eae1cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letters present in the Label Text\n",
    "letters= '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3faea7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image height\n",
    "img_h=90\n",
    "#image width\n",
    "img_w=280\n",
    "#image Channels\n",
    "img_c=1\n",
    "# classes for softmax with number of letters +1 for blank space in ctc\n",
    "num_classes=len(letters)+1\n",
    "batch_size=64\n",
    "max_length=5 # considering max length of ground truths labels to be 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f270a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words_labels(word):\n",
    "    \"\"\"\n",
    "    Encodes the Ground Truth Labels to a list of Values like eg.HAT returns [17,10,29]\n",
    "    \"\"\"\n",
    "    label_lst=[]\n",
    "    for char in word:\n",
    "        label_lst.append(letters.find(char)) # keeping 0 for blank and for padding labels\n",
    "    return label_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6783f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_from_labels(labels):\n",
    "    \"\"\"\n",
    "    converts the list of encoded integer labels to word strings like eg. [12,10,29] returns CAT \n",
    "    \"\"\"\n",
    "    txt=[]\n",
    "    for ele in labels:\n",
    "        if ele == len(letters): # CTC blank space\n",
    "            txt.append(\"\")\n",
    "        else:\n",
    "            #print(letters[ele])\n",
    "            txt.append(letters[ele])\n",
    "    return \"\".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55fa0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_loss_function(args):\n",
    "    \"\"\"\n",
    "    CTC loss function takes the values passed from the model returns the CTC loss using Keras Backend ctc_batch_cost function\n",
    "    \"\"\"\n",
    "    y_pred, y_true, input_length, label_length = args \n",
    "    # since the first couple outputs of the RNN tend to be garbage we need to discard them, found this from other CRNN approaches\n",
    "    # I Tried by including these outputs but the results turned out to be very bad and got very low accuracies on prediction \n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(y_true, y_pred, input_length, label_length)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cd83a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(keras.callbacks.Callback):\n",
    "    def __init__(self, img_dirpath, img_w, img_h,\n",
    "                 batch_size,n,output_labels,max_text_len=15):\n",
    "        self.img_h = img_h                    #Image Height\n",
    "        self.img_w = img_w                    #Image Width\n",
    "        self.batch_size = batch_size          #Batch size of Input\n",
    "        self.max_text_len = max_text_len      #Maximum Text length of Labels\n",
    "        \n",
    "#         self.n =len(self.img_dir)                           #Number of images in img_matrix\n",
    "        self.n=n\n",
    "        self.img_dir = img_dirpath[:self.n]     # images list\n",
    "        self.indexes = list(range(self.n))   #List of indices for each image in img_matrix\n",
    "        self.cur_index = 0                   #Current index which points to image being loaded \n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
    "        self.texts =  output_labels[:self.n]                  #List of Ground Truth Label texts\n",
    "\n",
    "   \n",
    "    def build_data(self):\n",
    "        \"\"\"\n",
    "        Build The Image Data\n",
    "        \"\"\"\n",
    "        print(self.n, \" Image Loading start...\")\n",
    "        for i, img_file in enumerate(self.img_dir):\n",
    "            img = cv2.imread(img_file)\n",
    "            img = img[:,:,1]                               #Extracting Single Channel Image\n",
    "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
    "            img = img /255\n",
    "            self.imgs[i, :, :]= img\n",
    "            if i%10000==0:\n",
    "                print(\"Loaded Images: \",i)\n",
    "           \n",
    "        print(\"Number of Texts matches with Total Number of Images :\",len(self.texts) == self.n)\n",
    "        print(self.n, \" Image Loading finish...\")\n",
    "\n",
    "\n",
    "    def next_data(self): \n",
    "        \"\"\"\n",
    "        Returns image and text data pointed by the current index\n",
    "        \"\"\"\n",
    "        self.cur_index += 1\n",
    "        #If current index becomes more than the number of images, make current index 0 \n",
    "        #and shuffle the indices list for random picking of image and text data\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
    "\n",
    "    def next_batch(self):\n",
    "        \"\"\"\n",
    "        Creates a batch of images images and text data equal to the batch_size,\n",
    "        computes the parameters needed for CTC and returns the inputs to the Model\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])  #Single channel Gray Size Scale images for input\n",
    "            #Initilizing with -1 to aid for padding labels of different lengths\n",
    "            Y_data = np.ones([self.batch_size, self.max_text_len])* -1        #Text labels for input\n",
    "           #input_length for CTC which is the number of time-steps of the RNN output\n",
    "            input_length = np.ones((self.batch_size, 1)) * 40\n",
    "            label_length = np.zeros((self.batch_size, 1))                   #label length for CTC\n",
    "            source_str=[]                                                   #List to store Ground Truth Labels\n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_data() #getting the image and text data pointed by current index\n",
    "                                    #taking transpose of image\n",
    "                img=img.T\n",
    "                img = np.expand_dims(img, -1)  #expanding image to have a single channel\n",
    "                X_data[i] = img\n",
    "                label=encode_words_labels(text) # encoding label text to integer list and storing in temp label variable\n",
    "                lbl_len=len(label)\n",
    "                Y_data[i,0:lbl_len] = label #Storing the label till its length and padding others\n",
    "                label_length[i] = len(label)\n",
    "                source_str.append(text) #storing Ground Truth Labels which will be accessed as reference for calculating metrics\n",
    "            \n",
    "        #Preparing the input for the Model\n",
    "            inputs = {\n",
    "                'img_input': X_data,  \n",
    "                'ground_truth_labels': Y_data,  \n",
    "                'input_length': input_length,  \n",
    "                'label_length': label_length,\n",
    "                'source_str': source_str  # used for visualization only\n",
    "            }\n",
    "            #Preparing output for the Model and intializing to zeros\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}  \n",
    "            yield (inputs, outputs) # Return the Prepared input and output to the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f767c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2dff9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPool2D, Dense,MaxPooling2D\n",
    "from keras.layers import AveragePooling2D, Flatten, Activation, Bidirectional\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Concatenate, Add, Multiply, Lambda\n",
    "from keras.layers import UpSampling2D, Reshape\n",
    "from keras.layers import add,concatenate # module merge no longer exists - need to use Concatenate instead\n",
    "from keras.layers import Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM,GRU # module recurrent no longer exists \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "01502a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_text_recogniser_model_1(stage,drop_out_rate=0.35):\n",
    "    \"\"\"\n",
    "    Builds the model by taking in the stage variable which specifes the stage,\n",
    "    if the stage is training: model takes inputs required for computing ctc_batch_cost function\n",
    "    else : model takes input as images which is used for prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "    print(input_shape)   \n",
    "    model_input=Input(shape=input_shape,name='img_input',dtype='float32')\n",
    "    print(model_input) \n",
    "    \n",
    "    # Convolution layer \n",
    "    model = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(model_input) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2), name='max1')(model) \n",
    "\n",
    "    model = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2), name='max2')(model) \n",
    "\n",
    "    model = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(model)\n",
    "    model=Dropout(drop_out_rate)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(1, 2), name='max3')(model)  \n",
    "\n",
    "    model = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(512, (3, 3), padding='same', name='conv6')(model)\n",
    "    model=Dropout(drop_out_rate)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(1, 2), name='max4')(model) \n",
    "\n",
    "    model = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(model)\n",
    "    model=Dropout(0.25)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)    \n",
    "\n",
    "    # CNN to RNN\n",
    "    \n",
    "    model = Reshape(target_shape=((70, 5, 512)), name='reshape')(model)  \n",
    "    model = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(model)  \n",
    "\n",
    "    # RNN layer\n",
    "    model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='sum')(model)\n",
    "    model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='concat')(model)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    model = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(model) \n",
    "    y_pred = Activation('softmax', name='softmax')(model)\n",
    "\n",
    "    \n",
    "    labels = Input(name='ground_truth_labels', shape=[max_length], dtype='float32') \n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64') \n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64') \n",
    "\n",
    "    #CTC loss function\n",
    "    loss_out = Lambda(ctc_loss_function, output_shape=(1,),name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n",
    "\n",
    "    if stage=='train':\n",
    "        return model_input,y_pred,Model(inputs=[model_input, labels, input_length, label_length], outputs=loss_out)\n",
    "    else:\n",
    "        return Model(inputs=[model_input], outputs=y_pred)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47664444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 90, 1)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 280, 90, 1), dtype=tf.float32, name='img_input'), name='img_input', description=\"created by layer 'img_input'\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"bidirectional_5\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 70, 5, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_input,y_pred,img_text_recog\u001b[38;5;241m=\u001b[39m\u001b[43mImage_text_recogniser_model_1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36mImage_text_recogniser_model_1\u001b[1;34m(stage, drop_out_rate)\u001b[0m\n\u001b[0;32m     53\u001b[0m model \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense1\u001b[39m\u001b[38;5;124m'\u001b[39m)(model)  \n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# RNN layer\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mBidirectional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhe_normal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerge_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m model\u001b[38;5;241m=\u001b[39mBidirectional(LSTM(\u001b[38;5;241m256\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m'\u001b[39m), merge_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m'\u001b[39m)(model)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# transforms RNN output to character activations:\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\rnn\\bidirectional.py:277\u001b[0m, in \u001b[0;36mBidirectional.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# Applies the same workaround as in `RNN.__call__`\u001b[39;00m\n\u001b[0;32m    280\u001b[0m additional_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:232\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    230\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m--> 232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"bidirectional_5\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 70, 5, 64)"
     ]
    }
   ],
   "source": [
    "model_input,y_pred,img_text_recog=Image_text_recogniser_model_1('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20927231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
